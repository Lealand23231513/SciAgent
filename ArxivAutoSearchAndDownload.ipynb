{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530acc9a",
   "metadata": {},
   "source": [
    "## 使用说明\n",
    "直接调用`arxiv_auto_search_and_download()`函数，会唤出输入，在输入中输入想要搜索下载的论文领域(任意语言)，即可自动搜索并下载。\n",
    "可以设置参数`top_k_results`，该参数用于**控制下载相关论文的数量**，默认为3。\n",
    "该函数还会以python字典的形式返回搜索结果，键值对为: **\"Title\": \"arxiv_id\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dfff715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, root_validator\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    " \n",
    "    \n",
    "def arxiv_auto_search_and_download(top_k_results = 3): \n",
    "    \n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "    class ArxivAPIWrapper(BaseModel):\n",
    "        \n",
    "        arxiv_search: Any  #: :meta private:\n",
    "        arxiv_exceptions: Any  # :meta private:\n",
    "        top_k_results: int = 3 \n",
    "        ARXIV_MAX_QUERY_LENGTH: int = 300\n",
    "        load_max_docs: int = 100\n",
    "        load_all_available_meta: bool = False\n",
    "        doc_content_chars_max: Optional[int] = 40000\n",
    "\n",
    "        @root_validator()\n",
    "        def validate_environment(cls, values: Dict) -> Dict:\n",
    "            \"\"\"Validate that the python package exists in environment.\"\"\"\n",
    "            try:\n",
    "                import arxiv\n",
    "\n",
    "                values[\"arxiv_search\"] = arxiv.Search\n",
    "                values[\"arxiv_exceptions\"] = (\n",
    "                    arxiv.ArxivError,\n",
    "                    arxiv.UnexpectedEmptyPageError,\n",
    "                    arxiv.HTTPError,\n",
    "                )\n",
    "                values[\"arxiv_result\"] = arxiv.Result\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"Could not import arxiv python package. \"\n",
    "                    \"Please install it with `pip install arxiv`.\"\n",
    "                )\n",
    "            return values\n",
    "\n",
    "        def run(self, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Performs an arxiv search and A single string\n",
    "            with the publish date, title, authors, and summary\n",
    "            for each article separated by two newlines.\n",
    "\n",
    "            If an error occurs or no documents found, error text\n",
    "            is returned instead. Wrapper for\n",
    "            https://lukasschwab.me/arxiv.py/index.html#Search\n",
    "\n",
    "            Args:\n",
    "                query: a plaintext search query\n",
    "            \"\"\"  # noqa: E501\n",
    "            try:\n",
    "                results = self.arxiv_search(  # type: ignore\n",
    "                    query[: self.ARXIV_MAX_QUERY_LENGTH], max_results=self.top_k_results\n",
    "                ).results()\n",
    "            except self.arxiv_exceptions as ex:\n",
    "                return f\"Arxiv exception: {ex}\"\n",
    "            docs = [\n",
    "                f\"Title: {result.title}\\n\"+ \n",
    "                f\"arxiv_id: {result.entry_id[21:]}\\n\"\n",
    "                for result in results\n",
    "            ]\n",
    "            if docs:\n",
    "                return \"\\n\\n\".join(docs)[: self.doc_content_chars_max]\n",
    "            else:\n",
    "                return \"No good Arxiv Result was found\"\n",
    "\n",
    "        def load(self, query: str) -> List[Document]:\n",
    "            \"\"\"\n",
    "            Run Arxiv search and get the article texts plus the article meta information.\n",
    "            See https://lukasschwab.me/arxiv.py/index.html#Search\n",
    "\n",
    "            Returns: a list of documents with the document.page_content in text format\n",
    "\n",
    "            Performs an arxiv search, downloads the top k results as PDFs, loads\n",
    "            them as Documents, and returns them in a List.\n",
    "\n",
    "            Args:\n",
    "                query: a plaintext search query\n",
    "            \"\"\"  # noqa: E501\n",
    "            try:\n",
    "                import fitz\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"PyMuPDF package not found, please install it with \"\n",
    "                    \"`pip install pymupdf`\"\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                # Remove the \":\" and \"-\" from the query, as they can cause search problems\n",
    "                query = query.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "                results = self.arxiv_search(  # type: ignore\n",
    "                    query[: self.ARXIV_MAX_QUERY_LENGTH], max_results=self.load_max_docs\n",
    "                ).results()\n",
    "            except self.arxiv_exceptions as ex:\n",
    "                logger.debug(\"Error on arxiv: %s\", ex)\n",
    "                return []\n",
    "\n",
    "            docs: List[Document] = []\n",
    "            for result in results:\n",
    "                try:\n",
    "                    doc_file_name: str = result.download_pdf()\n",
    "                    with fitz.open(doc_file_name) as doc_file:\n",
    "                        text: str = \"\".join(page.get_text() for page in doc_file)\n",
    "                except (FileNotFoundError, fitz.fitz.FileDataError) as f_ex:\n",
    "                    logger.debug(f_ex)\n",
    "                    continue\n",
    "                if self.load_all_available_meta:\n",
    "                    extra_metadata = {\n",
    "                        \"entry_id\": result.entry_id,\n",
    "                        \"published_first_time\": str(result.published.date()),\n",
    "                        \"comment\": result.comment,\n",
    "                        \"journal_ref\": result.journal_ref,\n",
    "                        \"doi\": result.doi,\n",
    "                        \"primary_category\": result.primary_category,\n",
    "                        \"categories\": result.categories,\n",
    "                        \"links\": [link.href for link in result.links],\n",
    "                    }\n",
    "                else:\n",
    "                    extra_metadata = {}\n",
    "                metadata = {\n",
    "                    \"Published\": str(result.updated.date()),\n",
    "                    \"Title\": result.title,\n",
    "                    \"Authors\": \", \".join(a.name for a in result.authors),\n",
    "                    \"entry_id\": result.entry_id,\n",
    "                    **extra_metadata,\n",
    "                }\n",
    "                doc = Document(\n",
    "                    page_content=text[: self.doc_content_chars_max], metadata=metadata\n",
    "                )\n",
    "                docs.append(doc)\n",
    "                os.remove(doc_file_name)\n",
    "            return docs\n",
    "\n",
    "    # 引入llm模型和agent代理\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0.0)\n",
    "    tools = load_tools(\n",
    "        [\"arxiv\"], \n",
    "    )\n",
    "\n",
    "    agent_chain = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # OpenAI的API调用函数\n",
    "\n",
    "    def get_completion(prompt, model = \"gpt-3.5-turbo\"):\n",
    "        messages = [{\"role\":\"user\",\"content\":prompt}]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            temperature = 0,\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"]\n",
    "\n",
    "    # 将arxiv的返回转换成字典\n",
    "\n",
    "    def string_to_dict(input_string):\n",
    "        paragraphs = input_string.strip().split('\\n\\n')\n",
    "        result_dict = {}\n",
    "        current_dict = {}\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            lines = paragraph.strip().split('\\n')\n",
    "\n",
    "            for line in lines:\n",
    "                key, value = map(str.strip, line.split(':', 1))\n",
    "                current_dict[key] = value\n",
    "\n",
    "            if current_dict:\n",
    "                result_dict[len(result_dict) + 1] = current_dict\n",
    "                current_dict = {}\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    # 传入arxivID和论文名称并将对应论文下载到当前目录\n",
    "\n",
    "    def download_arxiv_pdf(arxiv_id, name, folder_name):\n",
    "        pdf_url = 'https://arxiv.org/pdf/' + arxiv_id + '.pdf'\n",
    "\n",
    "        response = requests.get(pdf_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "\n",
    "            filename = os.path.join(folder_name, name + '.pdf')\n",
    "\n",
    "            with open(filename, 'wb') as pdf_file:\n",
    "                pdf_file.write(response.content)\n",
    "            print(f'文件 {filename} 下载成功！')\n",
    "        else:\n",
    "            print(f'下载失败，HTTP状态码: {response.status_code}')\n",
    "\n",
    "    # 获取用户输入并翻译成英文\n",
    "\n",
    "    question = input(f\"您好! 我是您的论文下载助手。\\n\\\n",
    "    请输入您想下载的论文的所属领域(单词即可)，我会自动查阅在Arxiv托管的论文中的相关论文并为您下载相关度最高的{top_k_results}篇到当前目录：\\n\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    请你将该单词翻译成英文，并且只返回翻译后的英文单词：{question}\n",
    "    \"\"\"\n",
    "    question = get_completion(prompt)\n",
    "\n",
    "    arxiv = ArxivAPIWrapper(top_k_results = top_k_results)\n",
    "    arxiv_result = arxiv.run(f\"\"\"{question}\"\"\")\n",
    "\n",
    "    result = string_to_dict(arxiv_result)\n",
    "\n",
    "    # 定义一个字符映射表并创建翻译表，用来替换文件名中不能出现的字符\n",
    "    char_mapping = {\n",
    "        '\\\\': ' ',  \n",
    "        '/': ' ',  \n",
    "        '?': ' ',  \n",
    "        ':': ' ', \n",
    "        '<': ' ', \n",
    "        '>': ' ', \n",
    "        '|': ' ', \n",
    "        '*': ' ', \n",
    "        '\"': ' ', \n",
    "    }\n",
    "    \n",
    "    translation_table = str.maketrans(char_mapping)\n",
    "\n",
    "\n",
    "    \n",
    "    # 循环遍历result中的每个结果并下载论文\n",
    "    for key,sub_dict in result.items():\n",
    "        Title = sub_dict.get(\"Title\").translate(translation_table) \n",
    "        download_arxiv_pdf(sub_dict.get(\"arxiv_id\"), Title, question)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5320ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好! 我是您的论文下载助手。\n",
      "    请输入您想下载的论文的所属领域(单词即可)，我会自动查阅在Arxiv托管的论文中的相关论文并为您下载相关度最高的5篇到当前目录：\n",
      "半导体\n",
      "文件 semiconductor\\Disappearing of the Fermi level pinning at semiconductor interfaces.pdf 下载成功！\n",
      "文件 semiconductor\\Optical Orientation in Ferromagnet Semiconductor Hybrids.pdf 下载成功！\n",
      "文件 semiconductor\\Refractive Indices of Semiconductors from Energy gaps.pdf 下载成功！\n",
      "文件 semiconductor\\Theoretical study of conventional semiconductors as transducers to increase power and efficiency in betavoltaic batteries.pdf 下载成功！\n",
      "文件 semiconductor\\Magnetic oxide semiconductors.pdf 下载成功！\n"
     ]
    }
   ],
   "source": [
    "result = arxiv_auto_search_and_download(top_k_results = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b02963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'Title': 'Disappearing of the Fermi level pinning at semiconductor interfaces', 'arxiv_id': '2202.10422v1'}, 2: {'Title': 'Optical Orientation in Ferromagnet/Semiconductor Hybrids', 'arxiv_id': '0803.4401v1'}, 3: {'Title': 'Refractive Indices of Semiconductors from Energy gaps', 'arxiv_id': '1508.03511v1'}, 4: {'Title': 'Theoretical study of conventional semiconductors as transducers to increase power and efficiency in betavoltaic batteries', 'arxiv_id': '2308.09807v1'}, 5: {'Title': 'Magnetic oxide semiconductors', 'arxiv_id': 'cond-mat/0504168v1'}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c5069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
